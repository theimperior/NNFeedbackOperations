{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norm (generic function with 16 methods)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"./dataManager.jl\")\n",
    "\n",
    "# Implementation of the Bottom Up Network with two Subversions: \n",
    "# BK with different Kernelsize and BF with different feature size\n",
    "using Flux, Statistics\n",
    "using Flux: onehot, onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON\n",
    "import LinearAlgebra: norm\n",
    "using NNlib\n",
    "\n",
    "using MAT # needs installation of Pkg.add(\"MAT\")\n",
    "using PyPlot # pip install Matplotlib Pkg.add(\"PyPlot\")\n",
    "using ..dataManager: make_batch\n",
    "# using FeedbackConvNets\n",
    "using Base\n",
    "# using CuArrays\n",
    "\n",
    "norm(x::TrackedArray{T}) where T = sqrt(sum(abs2.(x)) + eps(T)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "# ----------\n",
    "const batch_size = 100\n",
    "const n = 5\n",
    "const c = 1\n",
    "const alpha = Float32(10^-4)\n",
    "const beta = 0.5f0\n",
    "const lambda = 0.0005f0\n",
    "\n",
    "const kernelsize = (3, 3)\n",
    "const featuresize = 32\n",
    "\n",
    "const momentum = 0.9f0\n",
    "learningRate = 0.01f0\n",
    "const epochs = 100\n",
    "const decay_rate = 0.1f0\n",
    "const decay_step = 40\n",
    "\n",
    "train_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Constructing model...\n",
      "└ @ Main In[3]:1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>32, NNlib.relu), getfield(Main, Symbol(\"##3#6\"))(), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>32, NNlib.relu), getfield(Main, Symbol(\"##4#7\"))(), MaxPool((16, 16), pad = (0, 0, 0, 0), stride = (1, 1)), getfield(Main, Symbol(\"##5#8\"))(), Dense(32, 10, NNlib.σ))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@info(\"Constructing model...\")\n",
    "model = Chain(\n",
    "    # HIDDEN LAYER 1\n",
    "    # Input Image 32x32x1xN\n",
    "    Conv(kernelsize, 1=>featuresize, pad=(1,1), relu),\n",
    "    # local response normalization\n",
    "    x -> localResponseNorm(x),\n",
    "    MaxPool((2, 2), stride=(2, 2)),\n",
    "    \n",
    "    # HIDDEN LAYER 2\n",
    "    # Input Image 16x16x32xN\n",
    "    Conv(kernelsize, featuresize=>featuresize, pad=(1,1), relu),\n",
    "    # local response normalization\n",
    "    x -> localResponseNorm(x),\n",
    "    MaxPool((16, 16), stride=(1, 1)),\n",
    "    # reshape to 32xN\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(32, 10, σ),\n",
    ")\n",
    "\n",
    "# test the model (precomile it??)\n",
    "model = model |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_cb (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input is either 32x32x32xN or 16x16x32xN\n",
    "function localResponseNorm(x)\n",
    "    w = zeros(Float32, size(x))\n",
    "    for k = 1:size(x,3)\n",
    "        # calculate the boundaries of the sum\n",
    "        lower = Int32(max(1, floor(k-n/2)))\n",
    "        upper = Int32(min(size(x,3), floor(k+n/2)))\n",
    "        \n",
    "        # square and sum \n",
    "        # w = map((x) -> x^2, x[:, :, lower:upper, :])\n",
    "        norm = Tracker.data(x[:, :, lower:upper, :])\n",
    "        norm = norm .^ 2\n",
    "        # reduce to one 32x32x1xN or 16x16x1xN matrix\n",
    "        norm = sum(norm, dims=3)\n",
    "        norm = norm .* alpha\n",
    "        norm = norm .+ c\n",
    "        norm = norm .^ (-beta)\n",
    "        w[:, :, k, :] = norm\n",
    "    end   \n",
    "    # a tracked array multiplied with a non tracked array returns a tracked array  \n",
    "    x = w .* x\n",
    "    return x\n",
    "end\n",
    "\n",
    "function loss(x, y)\n",
    "    y_hat = model(x)\n",
    "    return crossentropy(y_hat, y) + lambda * sum(norm, params(model))\n",
    "end\n",
    "\n",
    "# gets called after every batch (learning step)\n",
    "function train_cb()\n",
    "    global train_idx\n",
    "    train_idx = train_idx + 1\n",
    "    @info(\"now at batch $(train_idx)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Reading .mat file form source ../digitclutter/src/light_debris/light_debris_with_debris.mat\n",
      "└ @ Main.dataManager C:\\Users\\Sebastian Vendt\\Git\\NNFeedbackOperations\\Src\\dataManager.jl:39\n",
      "┌ Info: calculate mean and standart deviation of dataset\n",
      "└ @ Main.dataManager C:\\Users\\Sebastian Vendt\\Git\\NNFeedbackOperations\\Src\\dataManager.jl:55\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "┌ Info: creating batches\n",
      "└ @ Main.dataManager C:\\Users\\Sebastian Vendt\\Git\\NNFeedbackOperations\\Src\\dataManager.jl:73\n",
      "┌ Info: Training...\n",
      "└ @ Main In[5]:6\n",
      "┌ Info: now at batch 1\n",
      "└ @ Main In[4]:33\n",
      "┌ Info: now at batch 2\n",
      "└ @ Main In[4]:33\n",
      "┌ Info: now at batch 3\n",
      "└ @ Main In[4]:33\n",
      "┌ Info: now at batch 4\n",
      "└ @ Main In[4]:33\n",
      "┌ Info: now at batch 5\n",
      "└ @ Main In[4]:33\n"
     ]
    }
   ],
   "source": [
    "# get the dataset\n",
    "train_set, mean_img, std_img = make_batch(batch_size=10)\n",
    "train_set = gpu.(train_set)\n",
    "model(train_set[1][1])\n",
    "\n",
    "@info(\"Training...\")\n",
    "optimizer = Momentum(learningRate, momentum)\n",
    "\n",
    "# training loop\n",
    "loss_val = loss(train_set[1][1], train_set[1][2])\n",
    "\n",
    "Flux.train!(loss, params(model), train_set, optimizer, cb = train_cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
