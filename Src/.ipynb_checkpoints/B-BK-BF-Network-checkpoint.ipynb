{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the Bottom Up Network with two Subversions: \n",
    "# BK with different Kernelsize and BF with different feature size\n",
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehot, onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON\n",
    "using LinearAlgebra\n",
    "\n",
    "using MAT # needs installation of Pkg.add(\"MAT\")\n",
    "using PyPlot # pip install Matplotlib Pkg.add(\"PyPlot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "# ----------\n",
    "batchsize = 100\n",
    "n = 5\n",
    "c = 1\n",
    "alpha = 10^-4\n",
    "beta = 0.5\n",
    "lambda = 0.0005\n",
    "\n",
    "kernelsize = (3, 3)\n",
    "featuresize = 32\n",
    "\n",
    "momentum = 0.9\n",
    "# TODO drop the learning rate according to the paper\n",
    "learningRate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load and process training data into batches\n",
    "# Data order in the .mat file \n",
    "# images: N_samples x 32 x 32 x 1\n",
    "# targets N_samples x 1\n",
    "# bin_targets: N_samples x 10\n",
    "\n",
    "file = matopen(\"../digitclutter/src/light_debris/light_debris_with_debris.mat\")\n",
    "images = read(file, \"images\")\n",
    "targets = read(file, \"targets\")\n",
    "bin_targets = read(file, \"binary_targets\")\n",
    "close(file) \n",
    "# rearrange the images array so it matches the convention of Flux width x height x channels x batchsize\n",
    "images = permutedims(images, (2, 3, 4, 1))\n",
    "\n",
    "# Display one sample of the images\n",
    "# matshow(dropdims(images[:,:,:,10], dims=3), cmap=PyPlot.cm.gray, vmin=0, vmax=255)#, cmap = gray, vmin=0, vmax=255)\n",
    "\n",
    "# SOURCE: https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "# Bundle images together with labels and group into minibatches\n",
    "# X should be of size \n",
    "# Y should be of size \n",
    "# X_batch is 32 x 32 x 1 x batchsize\n",
    "# Y_batch is 10 x batchsize\n",
    "function make_minibatch(X, Y, idxs)\n",
    "    # ... expands the inputarguments of the array construction to all sizes of X: size(X[1]), size(X[2]), size(X[3])\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:9) \n",
    "    return (X_batch, Y_batch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input is either 32x32x32xN or 16x16x32xN\n",
    "function localResponseNorm(x)\n",
    "    w = zeros(size(x))\n",
    "    for k = 1:size(x,3)\n",
    "        # calculate the boundaries of the sum\n",
    "        # ATTENTION: this will sum n+1 Elements\n",
    "        lower = Int32(max(1, round(k-n/2)))\n",
    "        upper = Int32(min(size(x,3), round(k+n/2)))\n",
    "        \n",
    "        # square and sum \n",
    "        # w = map((x) -> x^2, x[:, :, lower:upper, :])\n",
    "        norm = Tracker.data(x[:, :, lower:upper, :])\n",
    "        norm = norm .^ 2\n",
    "        # reduce to one 32x32x1xN or 16x16x1xN matrix\n",
    "        norm = sum(norm, dims=3)\n",
    "        norm = norm .* alpha\n",
    "        norm = norm .+ c\n",
    "        norm = norm .^ (-beta)\n",
    "        w[:, :, k, :] = norm\n",
    "    end   \n",
    "    # a tracked array multiplied with a non tracked array returns a tracked array  \n",
    "    x = w .* x\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(x, y)\n",
    "    y_hat = model(x)\n",
    "    return crossentropy(y_hat, y) + lambda * sum(norm, params(model))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info(\"Constructing model...\")\n",
    "model = Chain(\n",
    "    # HIDDEN LAYER 1\n",
    "    # Input Image 32x32x1xN\n",
    "    Conv(kernelsize, 1=>featuresize, pad=(1,1), relu),\n",
    "    # local response normalization\n",
    "    x -> localResponseNorm(x),\n",
    "    MaxPool((2, 2), stride=(2, 2)),\n",
    "    \n",
    "    # HIDDEN LAYER 2\n",
    "    # Input Image 16x16x32xN\n",
    "    Conv(kernelsize, featuresize=>featuresize, pad=(1,1), relu),\n",
    "    # local response normalization\n",
    "    x -> localResponseNorm(x),\n",
    "    MaxPool((16, 16), stride=(1, 1)),\n",
    "    # reshape to 32xN\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(32, 10, Ïƒ),\n",
    ")\n",
    "\n",
    "# test the model (precomile it??)\n",
    "model(rand(32, 32, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info(\"Training...\")\n",
    "optimizer = Momentum(learningRate, momentum)\n",
    "# using the momentum update rule\n",
    "\n",
    "label = zeros(10)\n",
    "label[3] = 1\n",
    "\n",
    "data = [(rand(32,32,1,1), label)]\n",
    "\n",
    "Flux.train!(loss, params(model), data, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.1",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
